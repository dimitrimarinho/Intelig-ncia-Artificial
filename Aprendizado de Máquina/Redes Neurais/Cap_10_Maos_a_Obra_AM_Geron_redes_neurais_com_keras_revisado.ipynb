{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Cap√≠tulo 10 ‚Äì Introdu√ß√£o √†s Redes Neurais Artificiais com Keras"
      ],
      "metadata": {
        "id": "DEB-Ccg_ZTLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Estes c√≥digos foram reproduzidos no Google Colab (recomenda-se o uso do Google Colab para reprodu√ß√£o integal)"
      ],
      "metadata": {
        "id": "D2C4__VOigV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configura√ß√£o"
      ],
      "metadata": {
        "id": "QephbD3yZWI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow ‚â•2.0 is required\n",
        "import tensorflow as tf\n",
        "\n",
        "# Importa√ß√µes comuns\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# para fazer esse notebook ter resultados repet√≠veis\n",
        "np.random.seed(42)\n",
        "\n",
        "# para plotar figuras\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "PROJECT_ROOT_DIR = \".\""
      ],
      "metadata": {
        "id": "4g3huB3zZaOq"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neur√¥nios biol√≥gicos"
      ],
      "metadata": {
        "id": "jQuGiw9fZlHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "C√©lula encontrada principalmente no c√≥rtex cerebral"
      ],
      "metadata": {
        "id": "WtI8MIsdZpjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Composto de um corpo celular contendo o n√∫cleo e a maioria dos componentes complexos da c√©lula e muitas extens√µes de ramifica√ß√£o chamadas dendritos, al√©m de uma extens√£o muito longa chamada de ax√¥nio\n",
        "\n",
        "* Os terminais sin√°pticos se conectam aos dendritos de outros neur√¥nios\n",
        "\n",
        "* Recebem sinais pelas sinapses\n",
        "\n",
        "* Os neur√¥nios biol√≥gicos recebem curtos impulsos el√©tricos de outros neur√¥nios atrav√©s dessas sinapses chamadas sinais.\n",
        "\n",
        "* Quando recebem sinais suficientes eles disparam seus sinais\n",
        "\n",
        "* Quando um neur√¥nio recebe um n√∫mero suficiente de sinais de outros neur√¥nios em alguns milissegundos, ele dispara seus pr√≥prios sinais"
      ],
      "metadata": {
        "id": "cztlzrC3ZqMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://i.imgur.com/iGaody9.png)"
      ],
      "metadata": {
        "id": "F3KB7ybZbX7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Neur√¥nios biol√≥gicos s√£o organizados em uma rede de bilh√µes de neur√¥nios conectados\n",
        "\n",
        "* C√°lculos altamente complexos podem ser realizados por uma vasta rede de neur√¥nios bem simples, muito parecida com um formigueiro complexo que surge dos esfor√ßos combinados de simples formigas.\n",
        "\n",
        "* Algumas partes do c√©rebro foram mapeadas e parece que os neur√¥nios muitas vezes s√£o organizados em camadas consecutivas, como mostrado na Figura abaixo."
      ],
      "metadata": {
        "id": "d-qItSLGbcA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://i.imgur.com/DG2FTaJ.png)"
      ],
      "metadata": {
        "id": "fuUpLocHb8rr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perceptrons"
      ],
      "metadata": {
        "id": "eCCL8AJFcD8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Inventado em 1957 por Frank Rosenblatt\n",
        "\n",
        "* O Perceptron √© uma das mais simples arquiteturas RNA.\n",
        "\n",
        "* Usa um neur√¥nio do tipo Linear Threshold Unit (LTU)"
      ],
      "metadata": {
        "id": "0kj8WHakcHmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://i.imgur.com/yncrihU.png)"
      ],
      "metadata": {
        "id": "NqtnzSTQcl9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A LTU calcula"
      ],
      "metadata": {
        "id": "anowyZcRcorv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* uma soma ponderada de suas entradas (ùëß = ùë§_1 ùë•_1 + ùë§_2 ùë•_2 + ‚ãØ + ùë§_ùëõ  ùë•_ùëõ = ùë§^ùëá. ùë•)\n",
        "\n",
        "* ent√£o aplica uma fun√ß√£o degrau a esta soma e gera o resultado ‚Ñé_ùë§ *(ùë•)= ùë†ùë°ùëíùëù(ùëß) em que ùëß = ùë§^ùëá\n",
        "\n",
        "* Treinar significa encontrar o pesos ideais."
      ],
      "metadata": {
        "id": "HDKDsvt3cpPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Perceptron √© composto por uma camada de LTUs como na figura abaixo."
      ],
      "metadata": {
        "id": "DLLCnCOidHNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://i.imgur.com/tGMF1GX.png)"
      ],
      "metadata": {
        "id": "EZLxDcRfdYGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Perceptron √© treinado com base na regra de Hebb\n"
      ],
      "metadata": {
        "id": "dqbZLZ5Zda9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* refor√ßando conex√µes que levam a previs√µes corretas\n",
        "\n",
        "* enfraquecendo conex√µes que levam a previs√µes incorretas"
      ],
      "metadata": {
        "id": "oru2G2XGdcza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimentando o Perceptron"
      ],
      "metadata": {
        "id": "g-5IucXxdiVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### O dataset Iris"
      ],
      "metadata": {
        "id": "Dpj8LYK5dklv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://i.imgur.com/qETsWGF.png)"
      ],
      "metadata": {
        "id": "FcrRzgq0eX31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris"
      ],
      "metadata": {
        "id": "kwXbMES1d4EU"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caracter√≠sticas:"
      ],
      "metadata": {
        "id": "2ZDTPaUJd6Wb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* comprimento de sepala em cm\n",
        "\n",
        "* largura de sepala em cm\n",
        "\n",
        "* comprimento de petala em cm\n",
        "\n",
        "* largura de petala em cm "
      ],
      "metadata": {
        "id": "vD2iXNBbd-2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classes:"
      ],
      "metadata": {
        "id": "nrWVux7zeK1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Iris-Setosa\n",
        "\n",
        "* Iris-Versicolour\n",
        "\n",
        "* Iris-Virginica\n"
      ],
      "metadata": {
        "id": "yC0p6hBPeNB4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "N√∫mero de inst√¢ncias = 150 (50 por classe)\n"
      ],
      "metadata": {
        "id": "1tAGQKPYebSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris();"
      ],
      "metadata": {
        "id": "bk47GLb2edFO"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados = iris[\"data\"];\n",
        "alvos = iris[\"target\"];\n",
        "nomesAlvo = iris[\"target_names\"];\n",
        "nomesCaracteristicas = iris[\"feature_names\"];"
      ],
      "metadata": {
        "id": "y8SeCmDwegGa"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nomesAlvo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbO_0sk7eiz8",
        "outputId": "41398e6d-313a-4951-8701-89c8eebab7b7"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nomesCaracteristicas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs4s_lQvelDC",
        "outputId": "46d9d9a4-b49e-4ca4-dcbc-458cfd7f9ab3"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QInsRwJGerv7",
        "outputId": "db243c93-207b-4051-e9f4-9edf02daa443"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alvos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhBWRnjLeuXo",
        "outputId": "44d9fbd0-9628-413f-98b8-20742ccef1e6"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQNtmggLexF4",
        "outputId": "28ebc4cd-04c5-40a2-fab9-d0e708e09c62"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1],\n",
              "        [5.4, 3.7, 1.5, 0.2],\n",
              "        [4.8, 3.4, 1.6, 0.2],\n",
              "        [4.8, 3. , 1.4, 0.1],\n",
              "        [4.3, 3. , 1.1, 0.1],\n",
              "        [5.8, 4. , 1.2, 0.2],\n",
              "        [5.7, 4.4, 1.5, 0.4],\n",
              "        [5.4, 3.9, 1.3, 0.4],\n",
              "        [5.1, 3.5, 1.4, 0.3],\n",
              "        [5.7, 3.8, 1.7, 0.3],\n",
              "        [5.1, 3.8, 1.5, 0.3],\n",
              "        [5.4, 3.4, 1.7, 0.2],\n",
              "        [5.1, 3.7, 1.5, 0.4],\n",
              "        [4.6, 3.6, 1. , 0.2],\n",
              "        [5.1, 3.3, 1.7, 0.5],\n",
              "        [4.8, 3.4, 1.9, 0.2],\n",
              "        [5. , 3. , 1.6, 0.2],\n",
              "        [5. , 3.4, 1.6, 0.4],\n",
              "        [5.2, 3.5, 1.5, 0.2],\n",
              "        [5.2, 3.4, 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.6, 0.2],\n",
              "        [4.8, 3.1, 1.6, 0.2],\n",
              "        [5.4, 3.4, 1.5, 0.4],\n",
              "        [5.2, 4.1, 1.5, 0.1],\n",
              "        [5.5, 4.2, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.2, 1.2, 0.2],\n",
              "        [5.5, 3.5, 1.3, 0.2],\n",
              "        [4.9, 3.6, 1.4, 0.1],\n",
              "        [4.4, 3. , 1.3, 0.2],\n",
              "        [5.1, 3.4, 1.5, 0.2],\n",
              "        [5. , 3.5, 1.3, 0.3],\n",
              "        [4.5, 2.3, 1.3, 0.3],\n",
              "        [4.4, 3.2, 1.3, 0.2],\n",
              "        [5. , 3.5, 1.6, 0.6],\n",
              "        [5.1, 3.8, 1.9, 0.4],\n",
              "        [4.8, 3. , 1.4, 0.3],\n",
              "        [5.1, 3.8, 1.6, 0.2],\n",
              "        [4.6, 3.2, 1.4, 0.2],\n",
              "        [5.3, 3.7, 1.5, 0.2],\n",
              "        [5. , 3.3, 1.4, 0.2],\n",
              "        [7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
              " 'frame': None,\n",
              " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
              " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
              " 'feature_names': ['sepal length (cm)',\n",
              "  'sepal width (cm)',\n",
              "  'petal length (cm)',\n",
              "  'petal width (cm)'],\n",
              " 'filename': 'iris.csv',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1, 2, 1)\n",
        "for contador, nome in enumerate(nomesAlvo):\n",
        "  x_plot = dados[ alvos == contador]\n",
        "  plt.plot(x_plot[:,0], x_plot[:,1], linestyle='none', marker='o', label=nome);\n",
        "\n",
        "plt.xlabel(nomesCaracteristicas[0]);\n",
        "plt.ylabel(nomesCaracteristicas[1]);\n",
        "plt.axis('equal');\n",
        "plt.legend();\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "for contador, nome in enumerate(nomesAlvo):\n",
        "  x_plot = dados[ alvos == contador]\n",
        "  plt.plot(x_plot[:,2], x_plot[:,3], linestyle='none', marker='o', label=nome);\n",
        "\n",
        "plt.xlabel(nomesCaracteristicas[2]);\n",
        "plt.ylabel(nomesCaracteristicas[3]);\n",
        "plt.axis('equal');\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "C3jv9JRKeyTB",
        "outputId": "245e79af-3cba-4980-a4d8-98a3a1f3e4b0"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classifica√ß√£o Bin√°ria"
      ],
      "metadata": {
        "id": "u-P-RIlShOIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimentando Perceptron com duas entradas e uma sa√≠da (2 Classes)"
      ],
      "metadata": {
        "id": "K9TkF0xBhW_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos simplificar e usar apenas comprimento da p√©tala e largura da p√©tala\n",
        "dadosReduzidos = dados[:, (2, 3)] # petal length, petal width\n",
        "dadosReduzidos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkRbANLJhZCh",
        "outputId": "902321fa-c5fc-45ef-8084-b0a6c02b42b4"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.4, 0.2],\n",
              "       [1.4, 0.2],\n",
              "       [1.3, 0.2],\n",
              "       [1.5, 0.2],\n",
              "       [1.4, 0.2],\n",
              "       [1.7, 0.4],\n",
              "       [1.4, 0.3],\n",
              "       [1.5, 0.2],\n",
              "       [1.4, 0.2],\n",
              "       [1.5, 0.1],\n",
              "       [1.5, 0.2],\n",
              "       [1.6, 0.2],\n",
              "       [1.4, 0.1],\n",
              "       [1.1, 0.1],\n",
              "       [1.2, 0.2],\n",
              "       [1.5, 0.4],\n",
              "       [1.3, 0.4],\n",
              "       [1.4, 0.3],\n",
              "       [1.7, 0.3],\n",
              "       [1.5, 0.3],\n",
              "       [1.7, 0.2],\n",
              "       [1.5, 0.4],\n",
              "       [1. , 0.2],\n",
              "       [1.7, 0.5],\n",
              "       [1.9, 0.2],\n",
              "       [1.6, 0.2],\n",
              "       [1.6, 0.4],\n",
              "       [1.5, 0.2],\n",
              "       [1.4, 0.2],\n",
              "       [1.6, 0.2],\n",
              "       [1.6, 0.2],\n",
              "       [1.5, 0.4],\n",
              "       [1.5, 0.1],\n",
              "       [1.4, 0.2],\n",
              "       [1.5, 0.2],\n",
              "       [1.2, 0.2],\n",
              "       [1.3, 0.2],\n",
              "       [1.4, 0.1],\n",
              "       [1.3, 0.2],\n",
              "       [1.5, 0.2],\n",
              "       [1.3, 0.3],\n",
              "       [1.3, 0.3],\n",
              "       [1.3, 0.2],\n",
              "       [1.6, 0.6],\n",
              "       [1.9, 0.4],\n",
              "       [1.4, 0.3],\n",
              "       [1.6, 0.2],\n",
              "       [1.4, 0.2],\n",
              "       [1.5, 0.2],\n",
              "       [1.4, 0.2],\n",
              "       [4.7, 1.4],\n",
              "       [4.5, 1.5],\n",
              "       [4.9, 1.5],\n",
              "       [4. , 1.3],\n",
              "       [4.6, 1.5],\n",
              "       [4.5, 1.3],\n",
              "       [4.7, 1.6],\n",
              "       [3.3, 1. ],\n",
              "       [4.6, 1.3],\n",
              "       [3.9, 1.4],\n",
              "       [3.5, 1. ],\n",
              "       [4.2, 1.5],\n",
              "       [4. , 1. ],\n",
              "       [4.7, 1.4],\n",
              "       [3.6, 1.3],\n",
              "       [4.4, 1.4],\n",
              "       [4.5, 1.5],\n",
              "       [4.1, 1. ],\n",
              "       [4.5, 1.5],\n",
              "       [3.9, 1.1],\n",
              "       [4.8, 1.8],\n",
              "       [4. , 1.3],\n",
              "       [4.9, 1.5],\n",
              "       [4.7, 1.2],\n",
              "       [4.3, 1.3],\n",
              "       [4.4, 1.4],\n",
              "       [4.8, 1.4],\n",
              "       [5. , 1.7],\n",
              "       [4.5, 1.5],\n",
              "       [3.5, 1. ],\n",
              "       [3.8, 1.1],\n",
              "       [3.7, 1. ],\n",
              "       [3.9, 1.2],\n",
              "       [5.1, 1.6],\n",
              "       [4.5, 1.5],\n",
              "       [4.5, 1.6],\n",
              "       [4.7, 1.5],\n",
              "       [4.4, 1.3],\n",
              "       [4.1, 1.3],\n",
              "       [4. , 1.3],\n",
              "       [4.4, 1.2],\n",
              "       [4.6, 1.4],\n",
              "       [4. , 1.2],\n",
              "       [3.3, 1. ],\n",
              "       [4.2, 1.3],\n",
              "       [4.2, 1.2],\n",
              "       [4.2, 1.3],\n",
              "       [4.3, 1.3],\n",
              "       [3. , 1.1],\n",
              "       [4.1, 1.3],\n",
              "       [6. , 2.5],\n",
              "       [5.1, 1.9],\n",
              "       [5.9, 2.1],\n",
              "       [5.6, 1.8],\n",
              "       [5.8, 2.2],\n",
              "       [6.6, 2.1],\n",
              "       [4.5, 1.7],\n",
              "       [6.3, 1.8],\n",
              "       [5.8, 1.8],\n",
              "       [6.1, 2.5],\n",
              "       [5.1, 2. ],\n",
              "       [5.3, 1.9],\n",
              "       [5.5, 2.1],\n",
              "       [5. , 2. ],\n",
              "       [5.1, 2.4],\n",
              "       [5.3, 2.3],\n",
              "       [5.5, 1.8],\n",
              "       [6.7, 2.2],\n",
              "       [6.9, 2.3],\n",
              "       [5. , 1.5],\n",
              "       [5.7, 2.3],\n",
              "       [4.9, 2. ],\n",
              "       [6.7, 2. ],\n",
              "       [4.9, 1.8],\n",
              "       [5.7, 2.1],\n",
              "       [6. , 1.8],\n",
              "       [4.8, 1.8],\n",
              "       [4.9, 1.8],\n",
              "       [5.6, 2.1],\n",
              "       [5.8, 1.6],\n",
              "       [6.1, 1.9],\n",
              "       [6.4, 2. ],\n",
              "       [5.6, 2.2],\n",
              "       [5.1, 1.5],\n",
              "       [5.6, 1.4],\n",
              "       [6.1, 2.3],\n",
              "       [5.6, 2.4],\n",
              "       [5.5, 1.8],\n",
              "       [4.8, 1.8],\n",
              "       [5.4, 2.1],\n",
              "       [5.6, 2.4],\n",
              "       [5.1, 2.3],\n",
              "       [5.1, 1.9],\n",
              "       [5.9, 2.3],\n",
              "       [5.7, 2.5],\n",
              "       [5.2, 2.3],\n",
              "       [5. , 1.9],\n",
              "       [5.2, 2. ],\n",
              "       [5.4, 2.3],\n",
              "       [5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OWiKi2ThafK",
        "outputId": "c8b500fd-34e9-4ca7-a1fe-d8d901c8f55b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alvos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3_PRCfvhcwx",
        "outputId": "4e4b4b1b-8ed8-4ee9-a5a0-6d5e82dea7da"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uma LTU s√≥ faz classifica√ß√£o bin√°ria\n",
        "classeAlvo = 0 # iris setosa\n",
        "alvos == classeAlvo # Iris setosa?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpxiLfOPhgaB",
        "outputId": "d0696719-e014-407a-a64d-86659a421d42"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convers√£o de l√≥gico para inteiro (true --> 1; false --> 0)\n",
        "alvoBinario = (alvos == classeAlvo).astype(int) # Iris setosa?\n",
        "alvoBinario"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbNkE1ymhilZ",
        "outputId": "6d6e1560-1605-4bbf-ae7c-5a701eb26226"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importando e treinando o Perceptron\n",
        "from sklearn.linear_model import Perceptron\n",
        "classificadorPerceptron = Perceptron()\n",
        "classificadorPerceptron.fit(dadosReduzidos, alvoBinario) # atributos de entrada e atributo alvo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XKNHHqIhmx4",
        "outputId": "87c17b48-a1bd-4354-cd5d-baf88a3afae3"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron()"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predizendo uma nova amostra (iris setosa)\n",
        "y_pred = classificadorPerceptron.predict([[1.5, 0.5]])\n",
        "if (y_pred):\n",
        "  print (\"iris setosa\")\n",
        "else:\n",
        "  print (\"outra flor\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2DTIzKMhvjn",
        "outputId": "2617b3e5-24bc-4fee-c931-cf4da6f786ff"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iris setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predizendo uma nova amostra (prevendo outra flor)\n",
        "y_pred = classificadorPerceptron.predict([[4, 1]])\n",
        "if (y_pred):\n",
        "  print (\"iris setosa\")\n",
        "else:\n",
        "  print (\"outra flor\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw6fb0EJhzZe",
        "outputId": "a018cb0b-d159-4f9f-9182-2053dedaf875"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outra flor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observando a matriz de pesos das conex√µes de entrada das LTU"
      ],
      "metadata": {
        "id": "EXbszTwBh4eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificadorPerceptron.coef_ # matriz de pesos de entrada"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoPFd3z7h8B2",
        "outputId": "a433e555-d7a2-4283-a07e-e1ff4bdb2823"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.7, -1.2]])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observando o peso de vies (entre o neuronio de vies e os neuronios LTU)"
      ],
      "metadata": {
        "id": "pAvcRJPdh92O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificadorPerceptron.intercept_ # matriz de pesos de vies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJdNgEDOiA5O",
        "outputId": "4eefb160-28b8-491c-d9b1-74894efb7552"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avaliando o Perceptron vendo o score com dados de treino"
      ],
      "metadata": {
        "id": "KJMgFYJhiEfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificadorPerceptron.score(dadosReduzidos,alvoBinario)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Lte8HMdiHl9",
        "outputId": "66e33ae3-89db-4b85-df25-3504d7f48724"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classifica√ß√£o Multiclasse (Multioutput)"
      ],
      "metadata": {
        "id": "DywYIYK_iMmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testando o Perceptron com 2 entradas e 3 sa√≠das (3 classes). Usando apenas comprimento da p√©tala e largura da p√©tala\n"
      ],
      "metadata": {
        "id": "s9amSs0BiPXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(alvos) # valores unicos da classe alvo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqHshPOEiSYc",
        "outputId": "e65e2128-8e5e-4458-c8bb-31cd7be35c9e"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classificadorPerceptron = Perceptron()\n",
        "classificadorPerceptron.fit(dadosReduzidos, alvos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "re2Qfzuuigl6",
        "outputId": "15f63f4d-c20e-495d-e9b6-c2e2e5f94a96"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron()"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predizendo uma nova amostra (setosa)\n",
        "y_pred = classificadorPerceptron.predict([[1.5, 0.5]])\n",
        "if (y_pred==0):\n",
        "  print (\"iris setosa\")\n",
        "elif (y_pred==1):\n",
        "  print (\"iris versicolor\")\n",
        "else:\n",
        "  print (\"iris virginica\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq9_qcqaijHT",
        "outputId": "e6e4e585-a7fe-42ff-9e7e-cf86a7cfabd6"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iris setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predizendo uma nova amostra (versicolor)\n",
        "y_pred = classificadorPerceptron.predict([[4, 1]])\n",
        "if (y_pred==0):\n",
        "  print (\"iris setosa\")\n",
        "elif (y_pred==1):\n",
        "  print (\"iris versicolor\")\n",
        "else:\n",
        "  print (\"iris virginica\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUnyasUPinub",
        "outputId": "36f14b73-5627-4882-dabf-cdadce5a120b"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iris versicolor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predizendo uma nova amostra (virginica)\n",
        "y_pred = classificadorPerceptron.predict([[6, 2]])\n",
        "if (y_pred==0):\n",
        "  print (\"iris setosa\")\n",
        "elif (y_pred==1):\n",
        "  print (\"iris versicolor\")\n",
        "else:\n",
        "  print (\"iris virginica\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVtSYFGSiwDx",
        "outputId": "f8e04187-6613-4d96-9970-0fdb7dc49ff0"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iris virginica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observando a matriz de pesos das conex√µes de entrada das LTU"
      ],
      "metadata": {
        "id": "mODBCWRuizr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificadorPerceptron.coef_ # 2 entradas, 3 sa√≠das"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eA8Xh74i2Di",
        "outputId": "7c52febc-135f-4533-9a4e-2959fe0ce737"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -2. ,  -3.6],\n",
              "       [  7.5, -17.6],\n",
              "       [  1.6,  31.1]])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observando o peso de vies (entre o neuronio de vies e os neuronios LTU)"
      ],
      "metadata": {
        "id": "QQg5_PZbjKwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificadorPerceptron.intercept_ # matriz de pesos de vies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XLycebwjRL5",
        "outputId": "e4b237c0-328d-489c-c123-bcc1c014cc53"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  7.,  -9., -52.])"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avaliando o Perceptron vendo o score com dados de treino"
      ],
      "metadata": {
        "id": "xJiAj402jTSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificadorPerceptron.score(dadosReduzidos,alvos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbWuEaPNjU8w",
        "outputId": "c6bab9e2-ebb6-4440-88fa-8f2237bc82df"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8733333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Atividade"
      ],
      "metadata": {
        "id": "W3LLl_Y-jYJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testar o Perceptron com 4 entradas e 3 sa√≠das.\n"
      ],
      "metadata": {
        "id": "mNVB93Dgja6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resposta: 4 entradas e 3 sa√≠das"
      ],
      "metadata": {
        "id": "HSf-t8fpB7Bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dados.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMfzXEIcCK5b",
        "outputId": "6d7a9e3a-89e9-4330-af7c-7a897c5fed01"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importando e treinando\n",
        "per_clf = Perceptron()\n",
        "per_clf.fit(dados, alvos) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GiF6sM3DMuC",
        "outputId": "be2ea9ab-647b-47fa-bfe5-d0bf30f85cef"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron()"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problemas com o Perceptron "
      ],
      "metadata": {
        "id": "JFfMPjpPDdBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em 1969, Marvin Minsky e Seymour Papert destacaram um n√∫mero de s√©rias fraquezas dos Perceptrons, em particular o fato de serem incapazes de resolver alguns problemas triviais (por exemplo, o problema de classifica√ß√£o Exclusive OR (XOR).\n"
      ],
      "metadata": {
        "id": "gNjAK_6oEPoQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Isso √© verdade para qualquer outro modelo de classifica√ß√£o linear (como classificadores de regress√£o log√≠stica), mas os pesquisadores esperavam muito mais dos Perceptrons, e alguns ficaram t√£o desapontados que abandonaram as redes neurais completamente em favor de problemas de n√≠vel superior, como l√≥gica, resolu√ß√£o de problemas e pesquisa. \n",
        "\n",
        "\n",
        "*   Come√ßou um inverno de IA \n",
        "\n"
      ],
      "metadata": {
        "id": "xHwitmagEdG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tabela verdade do XOR "
      ],
      "metadata": {
        "id": "IeO9sauME84c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://i.imgur.com/XI5Hpli.png)"
      ],
      "metadata": {
        "id": "n5ay9Ai7GdqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os cientistas preferiram se concentrar em outros classificadores como o SVM."
      ],
      "metadata": {
        "id": "tHc7aNFqGjt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# os cientistas preferiram se concentrar em outros classificadores como o SVM\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC # support vector classifier\n",
        "from sklearn.svm import LinearSVC\n",
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(dados, alvos) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e5iv1cDG0F6",
        "outputId": "e64460de-e747-4cbc-f5f2-8ecf5695117e"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('svc', SVC(gamma='auto'))])"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.score(dados,alvos) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDvePfeRIToR",
        "outputId": "7b0762f0-0278-4434-df72-766f9a2679d6"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9733333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### O perceptron multicamadas (rede neural) "
      ],
      "metadata": {
        "id": "GOtb1odIIYCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entretanto, algumas das suas limita√ß√µes podem ser eliminadas ao empilharmos v√°rios Perceptrons. A RNA resultante √© chamada de Perceptron Multicamada (MLP). Em particular, como voc√™ pode verificar, a MLP pode resolver o problema XOR calculando a sa√≠da MLP representada √† direita da Figura abaixo. "
      ],
      "metadata": {
        "id": "OFTSMwkjIeeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://i.imgur.com/rNruRZ9.png)"
      ],
      "metadata": {
        "id": "25mLgwLjKRSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://i.imgur.com/Gayj1Fo.png)"
      ],
      "metadata": {
        "id": "z8n3_ZCzKUUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outras fun√ß√µes de ativa√ß√£o "
      ],
      "metadata": {
        "id": "6dviwn5fK25l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A fun√ß√£o Step n√£o tem derivada, ent√£o ela limitava o Perceptron. Outras fun√ß√µes podem lidar com problemas n√£o lineares."
      ],
      "metadata": {
        "id": "IYGWYAF7LE5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://i.imgur.com/OTFyxqA.png)"
      ],
      "metadata": {
        "id": "tkkK7c4mMJkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimentando Rede Neural (antes de maiores detalhes) "
      ],
      "metadata": {
        "id": "DI8S-AMkMxx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "_H7FkZWvM5WB"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados = iris[\"data\"];\n",
        "alvos = iris[\"target\"];\n",
        "nomesAlvo = iris[\"target_names\"];\n",
        "nomesCaracteristicas = iris[\"feature_names\"];"
      ],
      "metadata": {
        "id": "0Av6vMHqN_-_"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qtd_saida = len(nomesAlvo); # numero de classes\n",
        "qtd_entrada = len(nomesCaracteristicas);  # numero de caracteristicas "
      ],
      "metadata": {
        "id": "DUqZ2W6QOM9l"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escalonando as caracter√≠sticas\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(dados) "
      ],
      "metadata": {
        "id": "JuboS8hdPAww"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dividindo o conjunto de treinamento e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, alvos, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "-x6ajY-yQtYw"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo a arquitetura da rede MLP \n",
        "# Unidades de sa√≠da, unidades de entrada, fun√ß√£o de ativa√ß√£o \n",
        "modelo = keras.Sequential([\n",
        "  keras.layers.Dense(16, input_dim=qtd_entrada, activation='relu'),\n",
        "  keras.layers.Dense(qtd_saida, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "U6l5LWJRT6Y0"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.summary() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9AQSS3lUQqo",
        "outputId": "08be3a36-55f7-490d-b1ed-c9aaf4ced427"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 16)                80        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 131\n",
            "Trainable params: 131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Outra forma de construir o modelo "
      ],
      "metadata": {
        "id": "m2emaPrJVkyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo a arquitetura da rede MLP\n",
        "# Unidades de sa√≠da, unidades de entrada, fun√ß√£o de ativa√ß√£o\n",
        "modelo = keras.Sequential(name ='modelo1')\n",
        "modelo.add(keras.layers.Dense(8, input_dim=qtd_entrada,activation='relu'))\n",
        "modelo.add(keras.layers.Dense(qtd_saida, activation='softmax')) "
      ],
      "metadata": {
        "id": "rILzNTtZVl_z"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.compile(loss='sparse_categorical_crossentropy',\n",
        "  optimizer=\"sgd\",\n",
        "  metrics=['accuracy']\n",
        ") "
      ],
      "metadata": {
        "id": "0lai0n9QWCKu"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Em Keras os argumentos de configura√ß√£o importantes s√£o os seguintes:**"
      ],
      "metadata": {
        "id": "3Ph2_bjPWP0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **N√∫mero de neur√¥nios/unidades na camada**  "
      ],
      "metadata": {
        "id": "pwVRxG2HWZcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Fun√ß√£o de ativa√ß√£o** (activation) - a fun√ß√£o de ativa√ß√£o √© uma fun√ß√£o especial usada para descobrir se um neur√¥nio espec√≠fico est√° ativado ou n√£o. Basicamente, a fun√ß√£o de ativa√ß√£o faz uma transforma√ß√£o n√£o linear dos dados de entrada e, assim, permite que os neur√¥nios aprendam melhor. A sa√≠da de um neur√¥nio depende da fun√ß√£o de ativa√ß√£o (*relu*, *sigmoid*, *tanh*, *exponential*, *softmax*)."
      ],
      "metadata": {
        "id": "g7FcBcy8WnqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Fun√ß√£o de Perda (loss)** - a fun√ß√£o Loss √© usada para encontrar erros ou desvios no processo de aprendizado (*mean_squared_error*, *mean_absolute_error*, *categorical_crossentropy*, *sparse_categorical_crossentropy*, *binary_crossentropy*)"
      ],
      "metadata": {
        "id": "9LUB_PWEXmHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Otimizador (optimizer)** - a otimiza√ß√£o √© um processo importante que otimiza os pesos de entrada comparando a previs√£o e a fun√ß√£o de perda (*sgd*, *rmsprop*, *adagrad*, *adadelta*, *adam*, *adamax*, *nadam*). "
      ],
      "metadata": {
        "id": "FKC0DvOzZBcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **M√©tricas (metrics)** - as m√©tricas s√£o usadas para avaliar o desempenho do seu modelo. √â semelhante √† fun√ß√£o de perda, mas n√£o √© usada no processo de treinamento (*accuracy*, *binary_accuracy*, *categorical_accuracy*, *sparse_categorical_accuracy*). "
      ],
      "metadata": {
        "id": "nnbmwgJ7ZWbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observa√ß√£o**"
      ],
      "metadata": {
        "id": "4A6WbzleZxGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Se estiv√©ssemos fazendo **classifica√ß√£o bin√°ria** (com um ou mais r√≥tulos bin√°rios), usar√≠amos a fun√ß√£o de ativa√ß√£o \"**sigmoid**\" (ou seja, log√≠stica) na camada de sa√≠da e usar√≠amos a fun√ß√£o de perda \"**binary_crossentropy**\". "
      ],
      "metadata": {
        "id": "3sZzG5LNZ0cQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Se estiv√©ssemos fazendo **classifica√ß√£o multiclasse**, usar√≠amos a fun√ß√£o de ativa√ß√£o \"**softmax**‚Äù e a fun√ß√£o de perda \"**sparse_categorical_crossentropy**' ou \"**categorical_crossentropy**‚Äô. "
      ],
      "metadata": {
        "id": "yJaG18bcaE-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Usamos a fun√ß√£o de perda \"**sparse_categorical_crossentropy**\" porque temos r√≥tulos esparsos (ou seja, para cada inst√¢ncia, h√° apenas um √≠ndice de classe de destino, de 0 a 2 neste caso), e as **classes s√£o exclusivas**. "
      ],
      "metadata": {
        "id": "0hyLm5QAad4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Se, em vez disso, tiv√©ssemos uma probabilidade alvo por classe para cada inst√¢ncia (como vetores one-hot, por exemplo, [0., 0., 1.] para representar a classe 3), ent√£o precisar√≠amos usar a fun√ß√£o de perda ‚Äú**categorical_crossentropy**‚Äù. "
      ],
      "metadata": {
        "id": "OWbZMFePay0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Treinando o Modelo\n",
        "historico = modelo.fit(X_train, y_train, epochs=200, validation_split=0.2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsJYWt2ZltBP",
        "outputId": "bf5b729a-815a-45a8-ba9d-8f6fa565c6bc"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 1.2414 - accuracy: 0.2000 - val_loss: 1.2556 - val_accuracy: 0.1000\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 1.2093 - accuracy: 0.2250 - val_loss: 1.2326 - val_accuracy: 0.1000\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.1788 - accuracy: 0.2500 - val_loss: 1.2106 - val_accuracy: 0.1500\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 1.1477 - accuracy: 0.3125 - val_loss: 1.1886 - val_accuracy: 0.1500\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.1190 - accuracy: 0.4000 - val_loss: 1.1671 - val_accuracy: 0.2000\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0917 - accuracy: 0.4375 - val_loss: 1.1474 - val_accuracy: 0.2000\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0658 - accuracy: 0.4750 - val_loss: 1.1283 - val_accuracy: 0.2500\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0420 - accuracy: 0.5125 - val_loss: 1.1109 - val_accuracy: 0.3500\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0198 - accuracy: 0.5375 - val_loss: 1.0945 - val_accuracy: 0.3500\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.9986 - accuracy: 0.5500 - val_loss: 1.0787 - val_accuracy: 0.4000\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.9782 - accuracy: 0.5625 - val_loss: 1.0629 - val_accuracy: 0.4000\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.9594 - accuracy: 0.5750 - val_loss: 1.0481 - val_accuracy: 0.4000\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9411 - accuracy: 0.6000 - val_loss: 1.0338 - val_accuracy: 0.4000\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.9239 - accuracy: 0.6125 - val_loss: 1.0208 - val_accuracy: 0.4000\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9076 - accuracy: 0.6250 - val_loss: 1.0077 - val_accuracy: 0.4000\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.8920 - accuracy: 0.6375 - val_loss: 0.9958 - val_accuracy: 0.4000\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.8770 - accuracy: 0.6375 - val_loss: 0.9838 - val_accuracy: 0.4000\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.8631 - accuracy: 0.6375 - val_loss: 0.9725 - val_accuracy: 0.4000\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.8494 - accuracy: 0.6875 - val_loss: 0.9616 - val_accuracy: 0.4000\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.8363 - accuracy: 0.6875 - val_loss: 0.9510 - val_accuracy: 0.4000\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.8234 - accuracy: 0.7000 - val_loss: 0.9411 - val_accuracy: 0.4000\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.8112 - accuracy: 0.7125 - val_loss: 0.9308 - val_accuracy: 0.4000\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.7993 - accuracy: 0.7125 - val_loss: 0.9210 - val_accuracy: 0.4000\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.7881 - accuracy: 0.7375 - val_loss: 0.9120 - val_accuracy: 0.5000\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.7772 - accuracy: 0.7625 - val_loss: 0.9029 - val_accuracy: 0.5000\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.7668 - accuracy: 0.7750 - val_loss: 0.8945 - val_accuracy: 0.5500\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.7570 - accuracy: 0.7875 - val_loss: 0.8860 - val_accuracy: 0.5500\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.7473 - accuracy: 0.8125 - val_loss: 0.8774 - val_accuracy: 0.6000\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.7382 - accuracy: 0.8250 - val_loss: 0.8696 - val_accuracy: 0.6500\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.7297 - accuracy: 0.8375 - val_loss: 0.8614 - val_accuracy: 0.6500\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.7210 - accuracy: 0.8375 - val_loss: 0.8535 - val_accuracy: 0.7000\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.7130 - accuracy: 0.8375 - val_loss: 0.8460 - val_accuracy: 0.7000\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.7053 - accuracy: 0.8250 - val_loss: 0.8386 - val_accuracy: 0.7500\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6976 - accuracy: 0.8375 - val_loss: 0.8315 - val_accuracy: 0.7500\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6903 - accuracy: 0.8375 - val_loss: 0.8249 - val_accuracy: 0.7500\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6833 - accuracy: 0.8375 - val_loss: 0.8179 - val_accuracy: 0.7500\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6763 - accuracy: 0.8375 - val_loss: 0.8116 - val_accuracy: 0.7500\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6699 - accuracy: 0.8375 - val_loss: 0.8052 - val_accuracy: 0.7500\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6636 - accuracy: 0.8375 - val_loss: 0.7984 - val_accuracy: 0.7000\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6572 - accuracy: 0.8375 - val_loss: 0.7927 - val_accuracy: 0.7000\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6509 - accuracy: 0.8375 - val_loss: 0.7866 - val_accuracy: 0.7000\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6450 - accuracy: 0.8375 - val_loss: 0.7808 - val_accuracy: 0.7000\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6390 - accuracy: 0.8375 - val_loss: 0.7756 - val_accuracy: 0.7000\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6334 - accuracy: 0.8375 - val_loss: 0.7704 - val_accuracy: 0.7000\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6279 - accuracy: 0.8375 - val_loss: 0.7653 - val_accuracy: 0.7000\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6226 - accuracy: 0.8375 - val_loss: 0.7599 - val_accuracy: 0.7000\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6174 - accuracy: 0.8375 - val_loss: 0.7542 - val_accuracy: 0.7000\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6119 - accuracy: 0.8375 - val_loss: 0.7491 - val_accuracy: 0.7000\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6069 - accuracy: 0.8375 - val_loss: 0.7439 - val_accuracy: 0.7000\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6024 - accuracy: 0.8375 - val_loss: 0.7391 - val_accuracy: 0.7000\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5971 - accuracy: 0.8375 - val_loss: 0.7332 - val_accuracy: 0.7000\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5920 - accuracy: 0.8250 - val_loss: 0.7277 - val_accuracy: 0.7000\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5872 - accuracy: 0.8250 - val_loss: 0.7230 - val_accuracy: 0.7000\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5826 - accuracy: 0.8250 - val_loss: 0.7180 - val_accuracy: 0.7000\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.5779 - accuracy: 0.8125 - val_loss: 0.7135 - val_accuracy: 0.7500\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.5737 - accuracy: 0.8125 - val_loss: 0.7085 - val_accuracy: 0.7500\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5690 - accuracy: 0.8125 - val_loss: 0.7041 - val_accuracy: 0.7500\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5650 - accuracy: 0.8125 - val_loss: 0.7003 - val_accuracy: 0.7500\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5609 - accuracy: 0.8125 - val_loss: 0.6958 - val_accuracy: 0.7500\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5566 - accuracy: 0.8125 - val_loss: 0.6914 - val_accuracy: 0.7500\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5526 - accuracy: 0.8125 - val_loss: 0.6872 - val_accuracy: 0.7500\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5488 - accuracy: 0.8125 - val_loss: 0.6832 - val_accuracy: 0.7500\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5448 - accuracy: 0.8125 - val_loss: 0.6787 - val_accuracy: 0.7500\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5410 - accuracy: 0.8125 - val_loss: 0.6740 - val_accuracy: 0.7500\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5370 - accuracy: 0.8125 - val_loss: 0.6700 - val_accuracy: 0.7500\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5332 - accuracy: 0.8125 - val_loss: 0.6659 - val_accuracy: 0.7500\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.5296 - accuracy: 0.8125 - val_loss: 0.6618 - val_accuracy: 0.7500\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5261 - accuracy: 0.8125 - val_loss: 0.6583 - val_accuracy: 0.7500\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5228 - accuracy: 0.8125 - val_loss: 0.6551 - val_accuracy: 0.7500\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5198 - accuracy: 0.8125 - val_loss: 0.6515 - val_accuracy: 0.7500\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5161 - accuracy: 0.8125 - val_loss: 0.6479 - val_accuracy: 0.7500\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5129 - accuracy: 0.8125 - val_loss: 0.6443 - val_accuracy: 0.7500\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5098 - accuracy: 0.8125 - val_loss: 0.6414 - val_accuracy: 0.7500\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.5067 - accuracy: 0.8125 - val_loss: 0.6376 - val_accuracy: 0.7500\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5035 - accuracy: 0.8125 - val_loss: 0.6346 - val_accuracy: 0.7500\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5005 - accuracy: 0.8125 - val_loss: 0.6313 - val_accuracy: 0.7500\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.4975 - accuracy: 0.8125 - val_loss: 0.6275 - val_accuracy: 0.7500\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4947 - accuracy: 0.8375 - val_loss: 0.6252 - val_accuracy: 0.7500\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4918 - accuracy: 0.8125 - val_loss: 0.6225 - val_accuracy: 0.7500\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.4890 - accuracy: 0.8125 - val_loss: 0.6195 - val_accuracy: 0.7500\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4863 - accuracy: 0.8250 - val_loss: 0.6168 - val_accuracy: 0.7500\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4837 - accuracy: 0.8375 - val_loss: 0.6138 - val_accuracy: 0.7500\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.4810 - accuracy: 0.8375 - val_loss: 0.6110 - val_accuracy: 0.7500\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.4783 - accuracy: 0.8375 - val_loss: 0.6082 - val_accuracy: 0.7500\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4758 - accuracy: 0.8375 - val_loss: 0.6058 - val_accuracy: 0.7500\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4732 - accuracy: 0.8375 - val_loss: 0.6032 - val_accuracy: 0.7500\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4707 - accuracy: 0.8375 - val_loss: 0.6007 - val_accuracy: 0.7500\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4683 - accuracy: 0.8375 - val_loss: 0.5987 - val_accuracy: 0.7500\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4658 - accuracy: 0.8375 - val_loss: 0.5961 - val_accuracy: 0.7500\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4636 - accuracy: 0.8375 - val_loss: 0.5935 - val_accuracy: 0.7500\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4611 - accuracy: 0.8375 - val_loss: 0.5908 - val_accuracy: 0.7500\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4587 - accuracy: 0.8375 - val_loss: 0.5881 - val_accuracy: 0.7500\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4563 - accuracy: 0.8375 - val_loss: 0.5860 - val_accuracy: 0.7500\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4539 - accuracy: 0.8375 - val_loss: 0.5833 - val_accuracy: 0.7500\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4517 - accuracy: 0.8375 - val_loss: 0.5815 - val_accuracy: 0.7500\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4499 - accuracy: 0.8375 - val_loss: 0.5793 - val_accuracy: 0.7500\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4474 - accuracy: 0.8375 - val_loss: 0.5769 - val_accuracy: 0.7500\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4453 - accuracy: 0.8375 - val_loss: 0.5748 - val_accuracy: 0.7500\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.4433 - accuracy: 0.8375 - val_loss: 0.5721 - val_accuracy: 0.7500\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4411 - accuracy: 0.8375 - val_loss: 0.5699 - val_accuracy: 0.7500\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4390 - accuracy: 0.8500 - val_loss: 0.5676 - val_accuracy: 0.7500\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4371 - accuracy: 0.8500 - val_loss: 0.5656 - val_accuracy: 0.7500\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.4350 - accuracy: 0.8500 - val_loss: 0.5634 - val_accuracy: 0.7500\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4331 - accuracy: 0.8500 - val_loss: 0.5613 - val_accuracy: 0.7500\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4313 - accuracy: 0.8500 - val_loss: 0.5594 - val_accuracy: 0.7500\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.4294 - accuracy: 0.8625 - val_loss: 0.5579 - val_accuracy: 0.7500\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4275 - accuracy: 0.8625 - val_loss: 0.5559 - val_accuracy: 0.7500\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4260 - accuracy: 0.8625 - val_loss: 0.5544 - val_accuracy: 0.7500\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4241 - accuracy: 0.8625 - val_loss: 0.5525 - val_accuracy: 0.7500\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4224 - accuracy: 0.8625 - val_loss: 0.5503 - val_accuracy: 0.8000\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4208 - accuracy: 0.8625 - val_loss: 0.5487 - val_accuracy: 0.8000\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.4190 - accuracy: 0.8625 - val_loss: 0.5462 - val_accuracy: 0.8000\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4172 - accuracy: 0.8625 - val_loss: 0.5443 - val_accuracy: 0.8000\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4155 - accuracy: 0.8625 - val_loss: 0.5423 - val_accuracy: 0.8000\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4138 - accuracy: 0.8625 - val_loss: 0.5408 - val_accuracy: 0.8000\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4123 - accuracy: 0.8625 - val_loss: 0.5391 - val_accuracy: 0.8000\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4107 - accuracy: 0.8625 - val_loss: 0.5372 - val_accuracy: 0.8000\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4090 - accuracy: 0.8625 - val_loss: 0.5358 - val_accuracy: 0.8000\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4076 - accuracy: 0.8625 - val_loss: 0.5341 - val_accuracy: 0.8000\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4062 - accuracy: 0.8625 - val_loss: 0.5328 - val_accuracy: 0.8000\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.4046 - accuracy: 0.8625 - val_loss: 0.5315 - val_accuracy: 0.8000\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4031 - accuracy: 0.8625 - val_loss: 0.5302 - val_accuracy: 0.8000\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.4017 - accuracy: 0.8625 - val_loss: 0.5290 - val_accuracy: 0.8000\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4008 - accuracy: 0.8625 - val_loss: 0.5280 - val_accuracy: 0.8000\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3990 - accuracy: 0.8625 - val_loss: 0.5260 - val_accuracy: 0.8000\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3974 - accuracy: 0.8625 - val_loss: 0.5248 - val_accuracy: 0.8000\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3960 - accuracy: 0.8625 - val_loss: 0.5237 - val_accuracy: 0.8000\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3948 - accuracy: 0.8625 - val_loss: 0.5220 - val_accuracy: 0.8000\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3933 - accuracy: 0.8625 - val_loss: 0.5206 - val_accuracy: 0.8000\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3920 - accuracy: 0.8625 - val_loss: 0.5192 - val_accuracy: 0.8000\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3908 - accuracy: 0.8625 - val_loss: 0.5180 - val_accuracy: 0.8000\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3897 - accuracy: 0.8625 - val_loss: 0.5167 - val_accuracy: 0.8000\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3882 - accuracy: 0.8750 - val_loss: 0.5153 - val_accuracy: 0.8000\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3871 - accuracy: 0.8750 - val_loss: 0.5140 - val_accuracy: 0.8000\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.3858 - accuracy: 0.8750 - val_loss: 0.5126 - val_accuracy: 0.8000\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.3845 - accuracy: 0.8750 - val_loss: 0.5118 - val_accuracy: 0.8000\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.3834 - accuracy: 0.8750 - val_loss: 0.5112 - val_accuracy: 0.8000\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3821 - accuracy: 0.8750 - val_loss: 0.5099 - val_accuracy: 0.8000\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3810 - accuracy: 0.8750 - val_loss: 0.5090 - val_accuracy: 0.8000\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3797 - accuracy: 0.8750 - val_loss: 0.5082 - val_accuracy: 0.8000\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3787 - accuracy: 0.8750 - val_loss: 0.5068 - val_accuracy: 0.8000\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3773 - accuracy: 0.8750 - val_loss: 0.5058 - val_accuracy: 0.8000\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.3763 - accuracy: 0.8750 - val_loss: 0.5048 - val_accuracy: 0.8000\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.3753 - accuracy: 0.8750 - val_loss: 0.5034 - val_accuracy: 0.8000\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3741 - accuracy: 0.8750 - val_loss: 0.5023 - val_accuracy: 0.8000\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.3730 - accuracy: 0.8750 - val_loss: 0.5014 - val_accuracy: 0.8000\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3721 - accuracy: 0.8750 - val_loss: 0.5005 - val_accuracy: 0.8000\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.3711 - accuracy: 0.8750 - val_loss: 0.4998 - val_accuracy: 0.8000\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.3699 - accuracy: 0.8750 - val_loss: 0.4990 - val_accuracy: 0.8000\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.3691 - accuracy: 0.8750 - val_loss: 0.4986 - val_accuracy: 0.8000\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3680 - accuracy: 0.8750 - val_loss: 0.4974 - val_accuracy: 0.8000\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3668 - accuracy: 0.8750 - val_loss: 0.4964 - val_accuracy: 0.8000\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3659 - accuracy: 0.8750 - val_loss: 0.4956 - val_accuracy: 0.8000\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3649 - accuracy: 0.8750 - val_loss: 0.4946 - val_accuracy: 0.8000\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3642 - accuracy: 0.8750 - val_loss: 0.4939 - val_accuracy: 0.8000\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.3631 - accuracy: 0.8750 - val_loss: 0.4931 - val_accuracy: 0.8000\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3623 - accuracy: 0.8750 - val_loss: 0.4928 - val_accuracy: 0.8000\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3612 - accuracy: 0.8750 - val_loss: 0.4923 - val_accuracy: 0.8000\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3604 - accuracy: 0.8750 - val_loss: 0.4913 - val_accuracy: 0.8000\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3596 - accuracy: 0.8750 - val_loss: 0.4901 - val_accuracy: 0.8000\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.3585 - accuracy: 0.8750 - val_loss: 0.4893 - val_accuracy: 0.8000\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3575 - accuracy: 0.8750 - val_loss: 0.4888 - val_accuracy: 0.8000\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3568 - accuracy: 0.8750 - val_loss: 0.4874 - val_accuracy: 0.8000\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3558 - accuracy: 0.8750 - val_loss: 0.4866 - val_accuracy: 0.8000\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3550 - accuracy: 0.8750 - val_loss: 0.4862 - val_accuracy: 0.8000\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3543 - accuracy: 0.8750 - val_loss: 0.4858 - val_accuracy: 0.8000\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3533 - accuracy: 0.8750 - val_loss: 0.4849 - val_accuracy: 0.8000\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3525 - accuracy: 0.8750 - val_loss: 0.4841 - val_accuracy: 0.8000\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.3517 - accuracy: 0.8750 - val_loss: 0.4834 - val_accuracy: 0.8000\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.3510 - accuracy: 0.8750 - val_loss: 0.4823 - val_accuracy: 0.8000\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3500 - accuracy: 0.8750 - val_loss: 0.4815 - val_accuracy: 0.8000\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3492 - accuracy: 0.8750 - val_loss: 0.4810 - val_accuracy: 0.8000\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3484 - accuracy: 0.8750 - val_loss: 0.4804 - val_accuracy: 0.8000\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3477 - accuracy: 0.8750 - val_loss: 0.4796 - val_accuracy: 0.8000\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3471 - accuracy: 0.8750 - val_loss: 0.4786 - val_accuracy: 0.8000\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3460 - accuracy: 0.8750 - val_loss: 0.4778 - val_accuracy: 0.8000\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.3452 - accuracy: 0.8750 - val_loss: 0.4772 - val_accuracy: 0.8000\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3446 - accuracy: 0.8750 - val_loss: 0.4767 - val_accuracy: 0.8000\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3437 - accuracy: 0.8750 - val_loss: 0.4763 - val_accuracy: 0.8000\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3432 - accuracy: 0.8750 - val_loss: 0.4757 - val_accuracy: 0.8000\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3421 - accuracy: 0.8750 - val_loss: 0.4749 - val_accuracy: 0.8000\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3416 - accuracy: 0.8750 - val_loss: 0.4747 - val_accuracy: 0.8000\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.3408 - accuracy: 0.8750 - val_loss: 0.4742 - val_accuracy: 0.8000\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.3400 - accuracy: 0.8750 - val_loss: 0.4735 - val_accuracy: 0.8000\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3393 - accuracy: 0.8750 - val_loss: 0.4732 - val_accuracy: 0.8000\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3386 - accuracy: 0.8750 - val_loss: 0.4730 - val_accuracy: 0.8000\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3379 - accuracy: 0.8750 - val_loss: 0.4727 - val_accuracy: 0.8000\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3371 - accuracy: 0.8750 - val_loss: 0.4721 - val_accuracy: 0.8000\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.3365 - accuracy: 0.8750 - val_loss: 0.4717 - val_accuracy: 0.8000\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.3358 - accuracy: 0.8875 - val_loss: 0.4707 - val_accuracy: 0.8000\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3351 - accuracy: 0.8750 - val_loss: 0.4701 - val_accuracy: 0.8000\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.3345 - accuracy: 0.8750 - val_loss: 0.4699 - val_accuracy: 0.8000\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.3339 - accuracy: 0.8875 - val_loss: 0.4689 - val_accuracy: 0.8000\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3333 - accuracy: 0.8750 - val_loss: 0.4682 - val_accuracy: 0.8000\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3325 - accuracy: 0.8750 - val_loss: 0.4679 - val_accuracy: 0.8000\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3319 - accuracy: 0.8875 - val_loss: 0.4673 - val_accuracy: 0.8000\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3313 - accuracy: 0.8875 - val_loss: 0.4662 - val_accuracy: 0.8000\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.3305 - accuracy: 0.8875 - val_loss: 0.4657 - val_accuracy: 0.8000\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3299 - accuracy: 0.8875 - val_loss: 0.4654 - val_accuracy: 0.8000\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3295 - accuracy: 0.8875 - val_loss: 0.4654 - val_accuracy: 0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construindo o Gr√°fico\n",
        "plt.plot(historico.history['accuracy'])\n",
        "plt.plot(historico.history['val_accuracy'])\n",
        "plt.title('Acur√°cia por √©poca')\n",
        "plt.xlabel('√©poca' )\n",
        "plt.ylabel('acur√°cia')\n",
        "plt.legend(['treino', 'valida√ß√£o'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "QDsRN8P-l4bX",
        "outputId": "bcf7e6b5-fc4a-43f7-e8c6-c5358d1eac25"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f2ce4156f50>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliando o modelo\n",
        "perda_teste, acuracia_teste = modelo.evaluate(X_test, y_test)\n",
        "print('Perda do teste:', perda_teste)\n",
        "print('Acur√°cia do teste:', acuracia_teste) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysIHRHHgmOfc",
        "outputId": "e8ff0005-f934-4dd7-ce69-3ffc77fd618f"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3698 - accuracy: 0.8400\n",
            "Perda do teste: 0.36984583735466003\n",
            "Acur√°cia do teste: 0.8399999737739563\n"
          ]
        }
      ]
    }
  ]
}